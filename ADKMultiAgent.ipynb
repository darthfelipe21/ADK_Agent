{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsZWGC5DawsN9TC8cqK+Yp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darthfelipe21/ADK_Agent/blob/main/ADKMultiAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# It takes a village: Multi-agent customer support\n"
      ],
      "metadata": {
        "id": "ktgOloNJFg9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🌐 Creating a Root Agent with Sub-Agents\n",
        "\n",
        "With multi-agents, each agent can specialize in a certain role, with a coordinator delegating tasks to the appropriate specialist.\n",
        "\n",
        "In our customer support example, imagine we want a more robust support assistant. We could break it into:\n",
        "\n",
        "- 👋 A **Greeting Agent**, handling greetings.\n",
        "- 🔑 An **Account Agent**, handling account access issues.\n",
        "- ❓ An **FAQ Agent**, using a pre-defined list of FAQs to answer common customer questions.\n",
        "- 🧭 A **Root Agent (Coordinator)** that receives the user’s query and decides which of the other agents should handle it, or handles it itself if it doesn’t fit any specialized category."
      ],
      "metadata": {
        "id": "vKiMLP80FkvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYp52sQ6EO-a"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==5.28.1 google-adk==1.0.0 litellm -q -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "importlib.invalidate_caches()"
      ],
      "metadata": {
        "id": "jqQV8fasFuii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.tools import FunctionTool\n",
        "from google import genai\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "import litellm\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n",
        "\n",
        "AGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "WG68KqdmFx6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import required libraries\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "nest_asyncio.apply()  # Required for async in notebooks\n",
        "\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.genai import types\n",
        "\n",
        "# Constants — define application, user, and session identifiers\n",
        "APP_NAME      = \"adk_course_app\"\n",
        "USER_ID       = \"user_123\"\n",
        "SESSION_ID    = \"support_session\""
      ],
      "metadata": {
        "id": "KU78ibNtF1Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FAQ knowledge base & tool\n",
        "FAQ_DATA = {\n",
        "    \"return policy\": \"You can return items within 30 days of purchase.\",\n",
        "    \"hours\": \"Our support team is available from 9 am to 5 pm, Monday to Friday.\",\n",
        "    \"contact\": \"You can reach support at help@example.com.\"\n",
        "}\n",
        "\n",
        "def lookup_faq(question: str) -> str:\n",
        "    faq_text = \"\\n\".join(f\"- {k}: {v}\" for k, v in FAQ_DATA.items())\n",
        "    prompt = (\n",
        "        f\"You are a helpful assistant. Here is a list of FAQs:\\n\\n{faq_text}\\n\\n\"\n",
        "        f\"User question: \\\"{question}\\\". \"\n",
        "        f\"Reply with the best match or say you don't know.\"\n",
        "    )\n",
        "    response = litellm.completion(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "faq_tool  = FunctionTool(func=lookup_faq)"
      ],
      "metadata": {
        "id": "5TFCVRJ4F40g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specialist Agents\n",
        "greeting_agent = LlmAgent(\n",
        "    name=\"GreetingAgent\",\n",
        "    description=\"Handles greetings from users.\",\n",
        "    instruction=\"Respond cheerfully when the user says hello.\",\n",
        "    model=AGENT_MODEL\n",
        ")\n",
        "\n",
        "account_agent = LlmAgent(\n",
        "    name=\"AccountAgent\",\n",
        "    description=\"Handles questions about login issues or account access.\",\n",
        "    instruction=\"Help users who are having trouble logging in or accessing their account.\",\n",
        "    model=AGENT_MODEL\n",
        ")\n",
        "\n",
        "faq_agent = LlmAgent(\n",
        "    name=\"FAQAgent\",\n",
        "    description=\"Answers common questions using the FAQ knowledge base.\",\n",
        "    instruction=\"Use the FAQ tool to answer questions that match the FAQs.\",\n",
        "    model=AGENT_MODEL,\n",
        "    tools=[faq_tool]\n",
        ")\n",
        "\n",
        "# Root agent with delegation logic\n",
        "root_agent = LlmAgent(\n",
        "    name=\"SupportRootAgent\",\n",
        "    description=\"Delegates to specialized sub-agents for support queries.\",\n",
        "    instruction=(\n",
        "        \"If the user greets you, delegate to GreetingAgent.\\n\"\n",
        "        \"If the user has an account or login issue, delegate to AccountAgent.\\n\"\n",
        "        \"If the question matches a known FAQ topic (e.g., returns, hours, contact), \"\n",
        "        \"delegate to FAQAgent. Do not answer as the FAQAgent if the topic doesn't match any of the FAQs.\\n\"\n",
        "        \"Otherwise, answer directly as best you (the Root Agent) can.\"\n",
        "    ),\n",
        "    model=AGENT_MODEL,\n",
        "    sub_agents=[greeting_agent, account_agent, faq_agent]\n",
        ")"
      ],
      "metadata": {
        "id": "4xgvkPIqF8bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Session & runner\n",
        "session_service = InMemorySessionService()\n",
        "await session_service.create_session(app_name=APP_NAME, user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "\n",
        "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "# Function to chat with the root agent\n",
        "async def call_agent_async(query: str):\n",
        "    print(f\"\\n>>> User Query: {query}\")\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    final_response = \"Agent did not produce a final response.\"\n",
        "\n",
        "    async for event in runner.run_async(user_id=USER_ID,\n",
        "                                        session_id=SESSION_ID,\n",
        "                                        new_message=content):\n",
        "        if event.is_final_response():\n",
        "            if event.content and event.content.parts:\n",
        "                final_response = event.content.parts[0].text\n",
        "            break\n",
        "\n",
        "    print(f\"<<< Agent {event.author}'s response: {final_response}\")\n",
        "\n",
        "# Test the full system\n",
        "await call_agent_async(\"Hello!\")                       # GreetingAgent\n",
        "await call_agent_async(\"I can't access my account.\")   # AccountAgent\n",
        "await call_agent_async(\"What is your return policy?\")  # FAQAgent\n",
        "await call_agent_async(\"I have a privacy question.\")   # SupportRootAgent"
      ],
      "metadata": {
        "id": "iiHot5DLGWSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}